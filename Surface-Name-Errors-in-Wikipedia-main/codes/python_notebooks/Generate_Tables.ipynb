{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/ssd/Dumps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Entity_Dict\n",
    "with open(file_path+\"title_to_loc.json\", \"r\", encoding='utf-8') as file:\n",
    "    Entity_Dict = json.load(file)\n",
    "    file.close()\n",
    "Entity_Dict2 ={}\n",
    "for x in Entity_Dict:\n",
    "    Entity_Dict2[x.lower()] = int(Entity_Dict[x][0])\n",
    "Entity_Dict = Entity_Dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-060fbe58d5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dict_3' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(file_path+'SN_Dict.json', 'r', encoding='utf-8') as file:\n",
    "    SN_Dict = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "with open(file_path+'Correct_Surface_Names.json','r', encoding='utf-8') as file:\n",
    "    Correct_Surface_Names = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "with open(file_path+'dest_SN_count.json','r', encoding='utf-8') as file:\n",
    "    Dict = json.load(file)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchism\n"
     ]
    }
   ],
   "source": [
    "for x in Entity_Dict:\n",
    "    if Entity_Dict[x] == 12:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done T1\n",
      "Done T2\n"
     ]
    }
   ],
   "source": [
    "#Generate table 1,2,5\n",
    "with open('Table5.txt','a', encoding='utf-8') as file:\n",
    "    file.write(\"Entity_ID, Surface_ID, Frequency, Correct/Wrong\\n\")\n",
    "    \n",
    "    for k,v in Dict.items():\n",
    "        if k in Correct_Surface_Names:\n",
    "            for k_,v_ in v.items():\n",
    "                if k in Entity_Dict:\n",
    "                    if k_ in Correct_Surface_Names[k]:\n",
    "                        file.write(\"{},{},{},1\\n\".format(Entity_Dict[k],SN_Dict[k_],Dict[k][k_]))\n",
    "                    else:\n",
    "                        file.write(\"{},{},{},0\\n\".format(Entity_Dict[k],SN_Dict[k_],Dict[k][k_]))\n",
    "\n",
    "\n",
    "    file.close()\n",
    "\n",
    "\n",
    "with open('Table1.txt','a', encoding='utf-8') as file:\n",
    "    file.write(\"Entity_Number, Entity_Name\\n\")\n",
    "    for k,v in Entity_Dict.items():\n",
    "        file.write(\"{},{}\\n\".format(v,k))\n",
    "    file.close()\n",
    "print(\"Done T1\")\n",
    "\n",
    "with open('Table2.txt','a', encoding='utf-8') as file:\n",
    "    file.write(\"SN_Number, SN_Name\\n\")\n",
    "    for k,v in SN_Dict.items():\n",
    "        file.write(\"{},{}\\n\".format(v,k))\n",
    "    file.close()\n",
    "print(\"Done T2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Table 6\n",
    "import csv\n",
    "import sys\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.reader(open(file_path+\"src_dest_SN.csv\",encoding='utf-8'), delimiter=\",\")\n",
    "def gen_reader():\n",
    "    for row in reader:\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path+'Edit_Distances.json','r',encoding='utf-8') as file:\n",
    "    Edit_Distances = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "with open(file_path+'Incorrect_Surface_Names.json','r',encoding='utf-8') as file:\n",
    "    Wrong_Surface_Names = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "with open(file_path+'Correct_Surface_Names.json','r',encoding='utf-8') as file:\n",
    "    Correct_Surface_Names = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "with open(file_path+'Substrings.json','r',encoding='utf-8') as file:\n",
    "    Substrings = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "with open(file_path+'Superstrings.json','r',encoding='utf-8') as file:\n",
    "    Superstrings = json.load(file)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "field larger than field limit (131072)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7320157e3e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Entity_Mention_index, Source_Entity_Index, Dest_Entity_Index, Surface_Name_Entity_Index, Sentence_ID, Condition(Less/More), Correct SN/Wrong SN, Edit-Distance, Recommended Surface-Name, Yes/No Superstring, Recommended Superstring, Yes/No Substring, Recommended Substring\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-f68ab5e2a86e>\u001b[0m in \u001b[0;36mgen_reader\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"src_dest_SN.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgen_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: field larger than field limit (131072)"
     ]
    }
   ],
   "source": [
    "mid = 1\n",
    "with open('Table6.txt','a',encoding='utf-8') as file:\n",
    "    file.write(\"Entity_Mention_index, Source_Entity_Index, Dest_Entity_Index, Surface_Name_Entity_Index, Sentence_ID, Condition(Less/More), Correct SN/Wrong SN, Edit-Distance, Recommended Surface-Name, Yes/No Superstring, Recommended Superstring, Yes/No Substring, Recommended Substring\\n\")\n",
    "\n",
    "    for row in gen_reader():\n",
    "        try:\n",
    "            sid = row[0]\n",
    "            sid = sid.lower()\n",
    "        except IndexError:\n",
    "            continue\n",
    "        try:\n",
    "            Source = row[1]\n",
    "            #Source = Source.lower()\n",
    "        except IndexError:\n",
    "            continue\n",
    "        try:\n",
    "            Dest = row[2]\n",
    "            #Dest = Dest.lower()\n",
    "        except IndexError:\n",
    "            continue\n",
    "        try:\n",
    "            surfaceName = row[3]\n",
    "            surfaceName = surfaceName.lower()\n",
    "        except IndexError:\n",
    "            continue\n",
    "        mid+=1\n",
    "        if Source not in Entity_Dict  or Dest not in Entity_Dict:\n",
    "            continue\n",
    "        line = \"{},{},{},{},{},\".format(mid,Entity_Dict[Source],Entity_Dict[Dest],SN_Dict[surfaceName],sid)\n",
    "\n",
    "    \n",
    "        if Dest in Correct_Surface_Names:\n",
    "            line += \"Equal or more than 3 surface-names,\"\n",
    "            if surfaceName in Correct_Surface_Names[Dest]:\n",
    "                line+=\"Correct\\n\"\n",
    "                continue\n",
    "            else:\n",
    "                line+=\"Wrong,\"\n",
    "                line+=\"{},{},\".format(Edit_Distances[Dest][surfaceName][1],SN_Dict[Edit_Distances[Dest][surfaceName][0]])\n",
    "                if surfaceName in Superstrings[Dest]:\n",
    "                    line += \"1,{},\".format(SN_Dict[Superstrings[Dest][surfaceName]])\n",
    "                else:\n",
    "                    line += \"0,NA,\"\n",
    "                if surfaceName in Substrings[Dest]:\n",
    "                    line += \"1,{}\\n\".format(SN_Dict[Substrings[Dest][surfaceName]])\n",
    "                else:\n",
    "                    line += \"0,NA\\n\"\n",
    "        else:\n",
    "            line+=\"Lesser-than-3-surface-names\\n\" \n",
    "            \n",
    "        \n",
    "        file.write(\"{}\".format(line))\n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114004234\n"
     ]
    }
   ],
   "source": [
    "print(mid) # number of mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6261930\n"
     ]
    }
   ],
   "source": [
    "print(len(Entity_Dict)) #no of Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000369\n"
     ]
    }
   ],
   "source": [
    "print(len(SN_Dict))   #No of Surface names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
